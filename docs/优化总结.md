# 设备数据分析系统优化总结

## 一、设计思路与目的

### 1.1 核心目标
优化设备数据分析系统的用户体验和功能完整性，主要解决：
- 历史记录显示问题
- 文件分析与表分析的 UI 区分
- 数据集导出功能

### 1.2 数据模型设计

#### 分析记录结构
```
AnalysisRecord
├── id                    -- 记录唯一标识
├── file_name             -- 原始文件名
├── table_name            -- 表名（表分析时使用）
├── analysis_type         -- 分析类型：general(文件分析) / table(表分析)
├── source_record_id      -- 原始记录ID（表分析时指向原始文件记录）
├── analysis_result       -- AI分析结果
└── status                -- 状态：pending / completed / analyzed
```

#### 设计意图
- **区分文件分析与表分析**：通过 `analysis_type` 字段区分
- **解决表数据获取**：新增 `source_record_id` 字段，让表分析记录指向原始文件记录的表数据

---

## 二、问题解决记录

### 2.1 历史记录名称显示问题

**问题描述**：
- 上传文件 `元件温度.mdb`
- 文件分析后：记录名称应为 `元件温度.mdb` ✓
- 表分析后：记录名称应为 `整流机组1` ✗（显示为 `元件温度.mdb`）

**问题原因**：
- 后端 `AnalysisRecordResponse` Schema 缺少 `table_name` 字段定义

**解决方案**：
```python
# backend/app/schemas/equipment.py
class AnalysisRecordResponse(AnalysisRecordBase):
    id: str
    table_name: Optional[str] = None  # 新增字段
    ...
```

### 2.2 表分析记录无法获取表数据

**问题描述**：
- 选择表分析记录后，数据集标签页显示 404 错误

**问题原因**：
- 表分析会创建新记录，有新 ID
- 但表数据（TableData）存储在原始记录 ID 下
- 新记录没有关联原始记录，导致找不到表数据

**解决方案**：
1. 新增 `source_record_id` 字段
```python
# backend/app/core/database.py
source_record_id = Column(String(36), nullable=True)
```

2. 创建表分析记录时保存原始记录 ID
```python
# backend/app/api/v1/endpoints.py
new_record = AnalysisRecord(
    ...
    source_record_id=request.record_id if request.table_name else None
)
```

3. 获取表数据时自动查找原始记录 ID
```python
# get_table_data 和 download_table_data 接口
record = db.query(AnalysisRecord).filter(AnalysisRecord.id == record_id).first()
actual_record_id = record_id
if record and record.source_record_id:
    actual_record_id = record.source_record_id
```

### 2.3 文件分析 vs 表分析 UI 区分

**问题描述**：
- 两种分析类型共用同一套 UI，不够直观

**解决方案**：
| 记录类型 | 显示名称 | 头部按钮 | 标签页 |
|---------|---------|---------|--------|
| 文件分析 | 文件名.mdb | 文件分析 | 数据表 |
| 表分析 | 表名 | 数据分析 | 数据集 |

### 2.4 加载提示优化

**问题描述**：
- 原加载动画不够友好

**解决方案**：
- 区分文件分析和表分析，显示不同提示和预计时间
- 全透明遮罩层，阻止页面操作

### 2.5 数据集导出 Excel

**问题描述**：
- 需要导出全量数据

**解决方案**：
1. 后端新增接口
```python
# GET /api/v1/records/{record_id}/tables/{table_name}/download
# 返回 Excel 文件
```

2. 前端添加导出按钮

---

## 三、关键代码修改

### 3.1 后端文件

| 文件 | 修改内容 |
|-----|---------|
| `app/core/database.py` | 新增 `source_record_id` 字段 |
| `app/schemas/equipment.py` | `AnalysisRecordResponse` 新增 `table_name` 和 `source_record_id` |
| `app/api/v1/endpoints.py` | - 创建记录时保存 `source_record_id`<br>- `get_table_data` 和 `download_table_data` 自动查找原始记录<br>- 新增下载接口 |

### 3.2 前端文件

| 文件 | 修改内容 |
|-----|---------|
| `src/App.vue` | - 历史记录显示：`table_name \|\| file_name`<br>- 头部名称显示<br>- 数据集/数据表标签页区分<br>- 导出 Excel 功能<br>- 加载提示优化 |
| `src/api/equipment.ts` | 新增 `downloadTableData` 方法 |

---

## 四、部署命令

### 4.1 服务器部署

```bash
# 1. 拉取代码
cd /opt/equipment-analysis
git pull origin main

# 2. 添加数据库字段
sqlite3 backend/equipment.db "ALTER TABLE analysis_records ADD COLUMN source_record_id VARCHAR(36);"

# 3. 安装 Python 依赖
pip3 install pandas openpyxl

# 4. 重启后端
pkill -f uvicorn
cd backend
nohup uvicorn app.main:app --host 0.0.0.0 --port 8001 > /tmp/uvicorn.log 2>&1 &

# 5. 构建并部署前端
cd ../frontend
npm run build
sudo cp -r dist/* /var/www/equipment-analysis/frontend/dist/
```

### 4.2 本地开发

```bash
# 前端
cd frontend
npm run dev

# 后端
cd backend
uvicorn app.main:app --reload
```

### 4.3 Nginx 超时配置

解决大文件上传和 AI 分析超时问题：

```bash
# 在 nginx 配置中添加
sudo sed -i '/proxy_request_buffering off;/a\        proxy_read_timeout 300s;' /etc/nginx/conf.d/default.conf
sudo nginx -s reload
```

---

## 五、数据库表结构

### 5.1 analysis_records 表

```sql
CREATE TABLE analysis_records (
    id VARCHAR(36) PRIMARY KEY,
    file_name VARCHAR(255) NOT NULL,
    file_size BIGINT,
    file_type VARCHAR(50),
    table_count INTEGER DEFAULT 0,
    record_count INTEGER DEFAULT 0,
    analysis_result JSON,
    table_name VARCHAR(255),
    analysis_type VARCHAR(20) DEFAULT 'general',
    source_record_id VARCHAR(36),  -- 新增：表分析时指向原始记录
    status VARCHAR(20) DEFAULT 'pending',
    error_message TEXT,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    completed_at DATETIME
);
```

### 5.2 table_data 表

```sql
CREATE TABLE table_data (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    record_id VARCHAR(36) NOT NULL,
    table_name VARCHAR(255) NOT NULL,
    columns TEXT,
    row_count INTEGER DEFAULT 0,
    data JSON,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

---

## 六、API 接口清单

| 方法 | 路径 | 说明 |
|-----|------|------|
| POST | `/api/v1/upload` | 上传文件 |
| GET | `/api/v1/records` | 获取历史记录列表 |
| GET | `/api/v1/records/{id}` | 获取单条记录 |
| DELETE | `/api/v1/records/{id}` | 删除记录 |
| GET | `/api/v1/records/{id}/tables` | 获取文件的所有表 |
| GET | `/api/v1/records/{id}/tables/{table_name}` | 获取表数据（分页） |
| GET | `/api/v1/records/{id}/tables/{table_name}/download` | 下载表数据 Excel |
| POST | `/api/v1/analyze` | AI 分析 |

---

## 七、版本历史

| 版本 | 日期 | 变更内容 |
|-----|------|---------|
| v1.0 | 2026-02-28 | 初始版本 |
| v1.1 | 2026-02-28 | 优化历史记录显示、UI区分、数据集导出 |

---

## 八、注意事项

1. **数据库字段添加**：每次新增字段后需在服务器执行 ALTER TABLE
2. **pandas 依赖**：导出 Excel 功能需要安装 `pandas` 和 `openpyxl`
3. **Nginx 超时**：AI 分析可能耗时较长，需配置超时时间
4. **表数据分析**：会创建新记录，通过 `source_record_id` 关联原始数据
